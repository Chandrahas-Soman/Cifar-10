{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project1_part1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "rx7VaTgm3MiL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "EE258 Project1 code"
      ]
    },
    {
      "metadata": {
        "id": "12IviFBpz_UJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-aDsElNy0G1y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load the data \n",
        "cifar10 = tf.keras.datasets.cifar10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drH16iUc1tVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a000e3f-f157-4654-c352-177cc2e03115"
      },
      "cell_type": "code",
      "source": [
        "type(cifar10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "module"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "OlD_wPv_128T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ca83da5e-0341-46d3-8540-47ab9e4605de"
      },
      "cell_type": "code",
      "source": [
        "# load the test and training data into seperate variables\n",
        "(x_train, y_train),(x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 25s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5h0thmw73D6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2d5b1431-1ad0-4ad1-f14e-5585f3211f49"
      },
      "cell_type": "code",
      "source": [
        "# Print the shapr of the training data and test data\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z_8Fs6V13HAI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "70b16a16-f65b-4745-f516-4eba966cfb5d"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[0])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYwrjWUwOk78AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc792df7e80>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "PWi04e4a4AEv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Developing a baseline model**"
      ]
    },
    {
      "metadata": {
        "id": "Boq0tw0b49-b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Choosing 3072 - 256 - 256 - 10 MLP model with ReLU and Softmax activation for baseline."
      ]
    },
    {
      "metadata": {
        "id": "Ps4q-ezF3-_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating a feed forward model \n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Flatten the image by taking 32*32*3 inputs\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(32, 32, 3)))\n",
        "\n",
        "# create a model with 3 hidden layers 328, 328 and 42 neurons respectively\n",
        "# use relu activation function in all the neurons \n",
        "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
        "\n",
        "# use softmax activation function in the output layer\n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YLzsoFoQ5mmY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# compile using stochastic gradient descent optimizer\n",
        "# use sparse_categorical_crossentropy as a metric for loss\n",
        "# use accuracy as a metric\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GjDPClTS6LZ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "c459c8d2-7de6-4387-9225-c70e00a15e31"
      },
      "cell_type": "code",
      "source": [
        "# model fitting\n",
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 15s 298us/step - loss: 14.5052 - acc: 0.1001\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 14s 290us/step - loss: 14.5063 - acc: 0.1000\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 15s 291us/step - loss: 14.5063 - acc: 0.1000\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 15s 292us/step - loss: 14.5063 - acc: 0.1000\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 15s 290us/step - loss: 14.5063 - acc: 0.1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc78c9a00f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "OQPGdkZmBExd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As we can see the accuracy is constantly low. One reason of this might be that we have not normalized our data. Let's do so and observe what happens."
      ]
    },
    {
      "metadata": {
        "id": "-meQ2AZhBXY7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# normalizing\n",
        "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
        "x_test = tf.keras.utils.normalize(x_test, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XZ5n4WQABs0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "9eb4ffaa-ecfa-4385-e897-377235449594"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[0])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc78c9a0240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UjYMouFOCBWj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets see the performance of the same model on normalized data."
      ]
    },
    {
      "metadata": {
        "id": "g8wHji6gCSa0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model is already built and compiled so lets just fit it."
      ]
    },
    {
      "metadata": {
        "id": "jU7BxR_4B5Ba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "d961ee1a-0431-4343-d04e-010fc91a9936"
      },
      "cell_type": "code",
      "source": [
        "# model fitting\n",
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 16s 314us/step - loss: 2.1894 - acc: 0.1934\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 2.0478 - acc: 0.2617\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.9817 - acc: 0.2944\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 1.9240 - acc: 0.3205\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 15s 297us/step - loss: 1.8724 - acc: 0.3397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc78c631da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "QFTWNfMKDA4q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As we can see good improvement per epoch let's increase number of epoch to see the performance of our model."
      ]
    },
    {
      "metadata": {
        "id": "8wSYhzL0DJkv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "d45f0e1f-d6a8-4ac8-fa96-51a960686065"
      },
      "cell_type": "code",
      "source": [
        "# improving the same model\n",
        "model.fit(x_train, y_train, epochs=25)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "50000/50000 [==============================] - 15s 295us/step - loss: 1.8295 - acc: 0.3559\n",
            "Epoch 2/25\n",
            "50000/50000 [==============================] - 15s 298us/step - loss: 1.7938 - acc: 0.3683\n",
            "Epoch 3/25\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 1.7637 - acc: 0.3789\n",
            "Epoch 4/25\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 1.7338 - acc: 0.3901\n",
            "Epoch 5/25\n",
            "50000/50000 [==============================] - 16s 319us/step - loss: 1.7092 - acc: 0.3988\n",
            "Epoch 6/25\n",
            "50000/50000 [==============================] - 16s 319us/step - loss: 1.6885 - acc: 0.4054\n",
            "Epoch 7/25\n",
            "50000/50000 [==============================] - 15s 301us/step - loss: 1.6675 - acc: 0.4132\n",
            "Epoch 8/25\n",
            "50000/50000 [==============================] - 16s 311us/step - loss: 1.6470 - acc: 0.4211\n",
            "Epoch 9/25\n",
            "50000/50000 [==============================] - 15s 298us/step - loss: 1.6287 - acc: 0.4279\n",
            "Epoch 10/25\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 1.6100 - acc: 0.4332\n",
            "Epoch 11/25\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 1.5941 - acc: 0.4378\n",
            "Epoch 12/25\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.5783 - acc: 0.4441\n",
            "Epoch 13/25\n",
            "50000/50000 [==============================] - 15s 301us/step - loss: 1.5635 - acc: 0.4504\n",
            "Epoch 14/25\n",
            "50000/50000 [==============================] - 15s 299us/step - loss: 1.5480 - acc: 0.4563\n",
            "Epoch 15/25\n",
            "50000/50000 [==============================] - 15s 299us/step - loss: 1.5339 - acc: 0.4593\n",
            "Epoch 16/25\n",
            "50000/50000 [==============================] - 15s 298us/step - loss: 1.5188 - acc: 0.4635\n",
            "Epoch 17/25\n",
            "50000/50000 [==============================] - 15s 301us/step - loss: 1.5069 - acc: 0.4704\n",
            "Epoch 18/25\n",
            "50000/50000 [==============================] - 15s 300us/step - loss: 1.4917 - acc: 0.4750\n",
            "Epoch 19/25\n",
            "50000/50000 [==============================] - 15s 298us/step - loss: 1.4772 - acc: 0.4800\n",
            "Epoch 20/25\n",
            "50000/50000 [==============================] - 15s 296us/step - loss: 1.4657 - acc: 0.4847\n",
            "Epoch 21/25\n",
            "50000/50000 [==============================] - 15s 307us/step - loss: 1.4553 - acc: 0.4856\n",
            "Epoch 22/25\n",
            "50000/50000 [==============================] - 15s 301us/step - loss: 1.4419 - acc: 0.4915\n",
            "Epoch 23/25\n",
            "50000/50000 [==============================] - 15s 301us/step - loss: 1.4295 - acc: 0.4977\n",
            "Epoch 24/25\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 1.4194 - acc: 0.4985\n",
            "Epoch 25/25\n",
            "50000/50000 [==============================] - 15s 301us/step - loss: 1.4073 - acc: 0.5058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc78c631240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "ALl5h8JwE2By",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So we can say that we have got a baseline training performance. But let's see how our network performs on unseen data to verify that our model hasn't just memorized."
      ]
    },
    {
      "metadata": {
        "id": "-8152j-REyBr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "fa2bdbd0-f3ea-414d-b2a1-42af1a49f54e"
      },
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
        "print(val_loss)\n",
        "print(val_acc)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 140us/step\n",
            "1.6169710195541382\n",
            "0.4251\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2l2FykpZGkiu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As we can see that training accuracy and test accuracy close to each other we can say that we are not overfitting the network and improve its performance."
      ]
    },
    {
      "metadata": {
        "id": "NntPeiB6G_u1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Improving the model**\n",
        "\n",
        "Lets start playing with the parameters. Lets change number of neurons, number of layers, learning rate, momentum, activation functions, batch size etc. \n",
        "\n",
        "If we want to have all possible permutations and combinations it will take forever, so we are choosing random values of parameters with constraint that no parameter values are close. e.g. model1 = 3 layers (3072 - 512 - 10) with activations functions tanh, softmax. while model2 = 5 layers (3072 - 384 - 384 - 48 - 10) with activation functions ReLU and softmax, adam optimizer. etc\n",
        "\n",
        "We are also keeping a few parameters constant like activation function of output layer to be softmax. We are also keeping number of epochs to be 30 for comparing perfomance of different models after the same number of iterations. "
      ]
    },
    {
      "metadata": {
        "id": "Crh63tiqOGSd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Lets calculate f1 score\n",
        "\n",
        "# Formula for f score is ----> F(β)=(1+β^2)⋅(PR/(ββP+R))\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, \"int32\")\n",
        "    y_pred = tf.cast(tf.round(y_pred), \"int32\") # implicit 0.5 threshold via tf.round\n",
        "    y_correct = y_true * y_pred\n",
        "    sum_true = tf.reduce_sum(y_true, axis=1)\n",
        "    sum_pred = tf.reduce_sum(y_pred, axis=1)\n",
        "    sum_correct = tf.reduce_sum(y_correct, axis=1)\n",
        "    precision = sum_correct / sum_pred\n",
        "    recall = sum_correct / sum_true\n",
        "    f_score = 2 * precision * recall / (precision + recall)\n",
        "    f_score = tf.where(tf.is_nan(f_score), tf.zeros_like(f_score), f_score)\n",
        "    return tf.reduce_mean(f_score)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cbJAb7jcZxXz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Model_1**"
      ]
    },
    {
      "metadata": {
        "id": "ebOUT70vG6r3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_1\n",
        "model_1 = tf.keras.models.Sequential()\n",
        "model_1.add(tf.keras.layers.Flatten(input_shape=(32, 32, 3)))\n",
        "model_1.add(tf.keras.layers.Dense(512, activation=tf.nn.tanh))\n",
        "model_1.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "model_1.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy',f1_score])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tGqj1RwaPn-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "e94e7953-e186-459c-ce40-0c6a63e6bebc"
      },
      "cell_type": "code",
      "source": [
        "model_1.fit(x_train, y_train, epochs=5)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 25s 502us/step - loss: 2.1148 - acc: 0.2351 - f1_score: 0.0093\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 24s 484us/step - loss: 2.0216 - acc: 0.2877 - f1_score: 0.0387\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 24s 483us/step - loss: 1.9844 - acc: 0.3042 - f1_score: 0.0622\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 24s 483us/step - loss: 1.9569 - acc: 0.3160 - f1_score: 0.0786\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 24s 489us/step - loss: 1.9360 - acc: 0.3269 - f1_score: 0.0927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc78ad754e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "xr8IleC1WTHg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Wonderful! Now that we have calculated f1 score, lets run this model for 30 epochs"
      ]
    },
    {
      "metadata": {
        "id": "hUiuV_R6WjNW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "f46d9f8e-f381-48a4-e31b-a79952edba73"
      },
      "cell_type": "code",
      "source": [
        "model_1.fit(x_train, y_train, epochs=25)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "50000/50000 [==============================] - 25s 494us/step - loss: 1.9197 - acc: 0.3362 - f1_score: 0.1095\n",
            "Epoch 2/25\n",
            "50000/50000 [==============================] - 24s 488us/step - loss: 1.9045 - acc: 0.3414 - f1_score: 0.1209\n",
            "Epoch 3/25\n",
            "50000/50000 [==============================] - 24s 489us/step - loss: 1.8929 - acc: 0.3463 - f1_score: 0.1321\n",
            "Epoch 4/25\n",
            "50000/50000 [==============================] - 25s 495us/step - loss: 1.8821 - acc: 0.3505 - f1_score: 0.1373\n",
            "Epoch 5/25\n",
            "50000/50000 [==============================] - 24s 489us/step - loss: 1.8727 - acc: 0.3558 - f1_score: 0.1471\n",
            "Epoch 6/25\n",
            "50000/50000 [==============================] - 24s 488us/step - loss: 1.8640 - acc: 0.3590 - f1_score: 0.1529\n",
            "Epoch 7/25\n",
            "50000/50000 [==============================] - 24s 489us/step - loss: 1.8562 - acc: 0.3616 - f1_score: 0.1599\n",
            "Epoch 8/25\n",
            "50000/50000 [==============================] - 25s 490us/step - loss: 1.8472 - acc: 0.3652 - f1_score: 0.1644\n",
            "Epoch 9/25\n",
            "50000/50000 [==============================] - 25s 493us/step - loss: 1.8383 - acc: 0.3709 - f1_score: 0.1728\n",
            "Epoch 10/25\n",
            "50000/50000 [==============================] - 25s 496us/step - loss: 1.8305 - acc: 0.3725 - f1_score: 0.1749\n",
            "Epoch 11/25\n",
            "50000/50000 [==============================] - 25s 493us/step - loss: 1.8243 - acc: 0.3738 - f1_score: 0.1835\n",
            "Epoch 12/25\n",
            "50000/50000 [==============================] - 26s 524us/step - loss: 1.8153 - acc: 0.3766 - f1_score: 0.1853\n",
            "Epoch 13/25\n",
            "50000/50000 [==============================] - 25s 495us/step - loss: 1.8078 - acc: 0.3815 - f1_score: 0.1925\n",
            "Epoch 14/25\n",
            "50000/50000 [==============================] - 25s 493us/step - loss: 1.7989 - acc: 0.3840 - f1_score: 0.1994\n",
            "Epoch 15/25\n",
            "50000/50000 [==============================] - 25s 494us/step - loss: 1.7914 - acc: 0.3879 - f1_score: 0.2063\n",
            "Epoch 16/25\n",
            "50000/50000 [==============================] - 24s 489us/step - loss: 1.7839 - acc: 0.3881 - f1_score: 0.2111\n",
            "Epoch 17/25\n",
            "50000/50000 [==============================] - 24s 485us/step - loss: 1.7761 - acc: 0.3898 - f1_score: 0.2171\n",
            "Epoch 18/25\n",
            "50000/50000 [==============================] - 25s 491us/step - loss: 1.7698 - acc: 0.3938 - f1_score: 0.2246\n",
            "Epoch 19/25\n",
            "50000/50000 [==============================] - 25s 492us/step - loss: 1.7622 - acc: 0.3960 - f1_score: 0.2264\n",
            "Epoch 20/25\n",
            "50000/50000 [==============================] - 24s 487us/step - loss: 1.7552 - acc: 0.3981 - f1_score: 0.2337\n",
            "Epoch 21/25\n",
            "50000/50000 [==============================] - 25s 492us/step - loss: 1.7469 - acc: 0.4003 - f1_score: 0.2424\n",
            "Epoch 22/25\n",
            "50000/50000 [==============================] - 25s 494us/step - loss: 1.7420 - acc: 0.4032 - f1_score: 0.2419\n",
            "Epoch 23/25\n",
            "50000/50000 [==============================] - 25s 494us/step - loss: 1.7354 - acc: 0.4060 - f1_score: 0.2472\n",
            "Epoch 24/25\n",
            "50000/50000 [==============================] - 26s 521us/step - loss: 1.7280 - acc: 0.4080 - f1_score: 0.2571\n",
            "Epoch 25/25\n",
            "50000/50000 [==============================] - 25s 503us/step - loss: 1.7208 - acc: 0.4082 - f1_score: 0.2567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc78b141710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "Cpyr83b0ZOcG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Model_2**\n"
      ]
    },
    {
      "metadata": {
        "id": "c6X3qpoGZHid",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_2 = tf.keras.models.Sequential()\n",
        "model_2.add(tf.keras.layers.Flatten(input_shape=(32, 32, 3)))\n",
        "model_2.add(tf.keras.layers.Dense(384, activation=tf.nn.relu))\n",
        "model_2.add(tf.keras.layers.Dense(384, activation=tf.nn.relu))\n",
        "model_2.add(tf.keras.layers.Dense(48, activation=tf.nn.relu))\n",
        "model_2.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "model_2.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy',f1_score])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8hwxEiiGaa39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "60d49673-135a-4651-e174-6cde17d73a72"
      },
      "cell_type": "code",
      "source": [
        "model_2.fit(x_train, y_train, epochs=5)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 36s 718us/step - loss: 2.0469 - acc: 0.2485 - f1_score: 0.0670\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 35s 704us/step - loss: 1.8663 - acc: 0.3294 - f1_score: 0.1675\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 36s 727us/step - loss: 1.7910 - acc: 0.3602 - f1_score: 0.2277\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 36s 713us/step - loss: 1.7387 - acc: 0.3777 - f1_score: 0.2765\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 36s 712us/step - loss: 1.6958 - acc: 0.3964 - f1_score: 0.3145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc78a871d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "aXLmrr2bbN3a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This model looks promising. Just after 5 iterarations the accuracy is almost 40%.  "
      ]
    },
    {
      "metadata": {
        "id": "k08Ij4RDblns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "c1486b92-692c-4ebb-e01b-06f2f83b4014"
      },
      "cell_type": "code",
      "source": [
        "model_2.fit(x_train, y_train, epochs=25)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "50000/50000 [==============================] - 36s 714us/step - loss: 1.6640 - acc: 0.4060 - f1_score: 0.3494\n",
            "Epoch 2/25\n",
            "50000/50000 [==============================] - 35s 706us/step - loss: 1.6366 - acc: 0.4180 - f1_score: 0.3757\n",
            "Epoch 3/25\n",
            "50000/50000 [==============================] - 35s 706us/step - loss: 1.6096 - acc: 0.4277 - f1_score: 0.3985\n",
            "Epoch 4/25\n",
            "50000/50000 [==============================] - 35s 703us/step - loss: 1.5884 - acc: 0.4351 - f1_score: 0.4181\n",
            "Epoch 5/25\n",
            "50000/50000 [==============================] - 35s 709us/step - loss: 1.5612 - acc: 0.4447 - f1_score: 0.4387\n",
            "Epoch 6/25\n",
            "50000/50000 [==============================] - 36s 716us/step - loss: 1.5409 - acc: 0.4504 - f1_score: 0.4564\n",
            "Epoch 7/25\n",
            "50000/50000 [==============================] - 38s 755us/step - loss: 1.5187 - acc: 0.4589 - f1_score: 0.4778\n",
            "Epoch 8/25\n",
            "50000/50000 [==============================] - 36s 718us/step - loss: 1.5036 - acc: 0.4646 - f1_score: 0.4923\n",
            "Epoch 9/25\n",
            "50000/50000 [==============================] - 36s 724us/step - loss: 1.4866 - acc: 0.4699 - f1_score: 0.5084\n",
            "Epoch 10/25\n",
            "50000/50000 [==============================] - 37s 735us/step - loss: 1.4700 - acc: 0.4783 - f1_score: 0.5228\n",
            "Epoch 11/25\n",
            "50000/50000 [==============================] - 37s 734us/step - loss: 1.4510 - acc: 0.4838 - f1_score: 0.5411\n",
            "Epoch 12/25\n",
            "50000/50000 [==============================] - 37s 734us/step - loss: 1.4388 - acc: 0.4884 - f1_score: 0.5587\n",
            "Epoch 13/25\n",
            "50000/50000 [==============================] - 36s 730us/step - loss: 1.4280 - acc: 0.4903 - f1_score: 0.5714\n",
            "Epoch 14/25\n",
            "50000/50000 [==============================] - 36s 726us/step - loss: 1.4087 - acc: 0.4972 - f1_score: 0.5800\n",
            "Epoch 15/25\n",
            "50000/50000 [==============================] - 38s 761us/step - loss: 1.3949 - acc: 0.5020 - f1_score: 0.5923\n",
            "Epoch 16/25\n",
            "50000/50000 [==============================] - 37s 731us/step - loss: 1.3844 - acc: 0.5066 - f1_score: 0.6047\n",
            "Epoch 17/25\n",
            "50000/50000 [==============================] - 37s 735us/step - loss: 1.3672 - acc: 0.5136 - f1_score: 0.6131\n",
            "Epoch 18/25\n",
            "50000/50000 [==============================] - 37s 736us/step - loss: 1.3584 - acc: 0.5160 - f1_score: 0.6299\n",
            "Epoch 19/25\n",
            "50000/50000 [==============================] - 37s 737us/step - loss: 1.3457 - acc: 0.5208 - f1_score: 0.6439\n",
            "Epoch 20/25\n",
            "50000/50000 [==============================] - 37s 733us/step - loss: 1.3364 - acc: 0.5240 - f1_score: 0.6531\n",
            "Epoch 21/25\n",
            "50000/50000 [==============================] - 37s 748us/step - loss: 1.3202 - acc: 0.5279 - f1_score: 0.6647\n",
            "Epoch 22/25\n",
            "50000/50000 [==============================] - 36s 726us/step - loss: 1.3105 - acc: 0.5326 - f1_score: 0.6723\n",
            "Epoch 23/25\n",
            "50000/50000 [==============================] - 36s 725us/step - loss: 1.3012 - acc: 0.5356 - f1_score: 0.6798\n",
            "Epoch 24/25\n",
            "50000/50000 [==============================] - 38s 764us/step - loss: 1.2900 - acc: 0.5396 - f1_score: 0.6896\n",
            "Epoch 25/25\n",
            "50000/50000 [==============================] - 36s 721us/step - loss: 1.2809 - acc: 0.5410 - f1_score: 0.7026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc78aaf7320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "HGri7kikfg-5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can say that this model is better than our baseline model. Let's verify it using different validation splits."
      ]
    },
    {
      "metadata": {
        "id": "6cJSFunAguPc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model is same but we are going to perform different validation splits on it.\n"
      ]
    },
    {
      "metadata": {
        "id": "lrvFurZTiShW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "8a57066b-1765-4263-a32f-d6ffdd7d14f2"
      },
      "cell_type": "code",
      "source": [
        "model_2.fit(x_train, y_train, validation_split = 0.2, epochs=3)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "40000/40000 [==============================] - 32s 790us/step - loss: 1.2646 - acc: 0.5487 - f1_score: 0.7100 - val_loss: 1.2399 - val_acc: 0.5576 - val_f1_score: 0.7009\n",
            "Epoch 2/3\n",
            "40000/40000 [==============================] - 30s 747us/step - loss: 1.2463 - acc: 0.5562 - f1_score: 0.7327 - val_loss: 1.2819 - val_acc: 0.5382 - val_f1_score: 0.7161\n",
            "Epoch 3/3\n",
            "40000/40000 [==============================] - 30s 746us/step - loss: 1.2376 - acc: 0.5603 - f1_score: 0.7397 - val_loss: 1.2899 - val_acc: 0.5414 - val_f1_score: 0.7253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc789f55588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "NP0DOV91jAfY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets change the size of validation set."
      ]
    },
    {
      "metadata": {
        "id": "leqiDnDwjEEc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "a470f0a4-bb36-4e9f-85f4-b56e28795879"
      },
      "cell_type": "code",
      "source": [
        "model_2.fit(x_train, y_train, validation_split = 0.33, epochs=3)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 33500 samples, validate on 16500 samples\n",
            "Epoch 1/3\n",
            "33500/33500 [==============================] - 26s 776us/step - loss: 1.2184 - acc: 0.5671 - f1_score: 0.7514 - val_loss: 1.3357 - val_acc: 0.5230 - val_f1_score: 0.7053\n",
            "Epoch 2/3\n",
            "33500/33500 [==============================] - 27s 793us/step - loss: 1.2021 - acc: 0.5720 - f1_score: 0.7661 - val_loss: 1.2853 - val_acc: 0.5434 - val_f1_score: 0.7353\n",
            "Epoch 3/3\n",
            "33500/33500 [==============================] - 26s 785us/step - loss: 1.1855 - acc: 0.5796 - f1_score: 0.7805 - val_loss: 1.3040 - val_acc: 0.5338 - val_f1_score: 0.7406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc789fd04a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "YOZ-1PjEjhgv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see that as we changed validation split from 0.2 to 0.33 difference between accuracy and validation accuracy increased. Therefore, We can say that validation split of 0.2 is better than 0.33. \n",
        "\n",
        "Let's go to project part 2 now."
      ]
    }
  ]
}